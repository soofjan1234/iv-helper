## 为什么不选 ES 或 MS 而是bleve？

在搜索引擎选型中，我们优先考虑部署复杂度与空间占用。ES虽然功能强大，但更适用于大规模分布式场景，对于资源敏感的nas产品来说 内存占用巨大，默认消耗 1-2GB，同时需要 Java 环境；Meilisearch降低了使用门槛，但仍需独立部署。

 Bleve，就像sqlite，完全嵌入式，同时是go原生，无需额外服务，从而降低运维成本并提升部署效率。

## 三者性能对比

在中小规模数据场景下，Bleve 的查询延迟往往更低，因为其嵌入式架构，避免了网络通信与序列化开销；但在超大规模数据和高并发场景下，Elasticsearch 的分布式能力更具优势

## 为什么要加入ai搜索，失败了怎么办？

流程是用户输入 → GPT 提取关键词/同义词 → 拼接原查询，因为用户可能无法想到准确的词，如搜"AI"能匹配"人工智能”

我们用的是go resty，超时会直接走原始搜索，同时ai搜索得到的结果会存到缓存Ristretto半小时

## 如何解析这些文件的？是否有容错

1. 不管什么格式，调用方只用 ParseFileContent(path) 就能拿到纯文本
2. **编码处理**：用 chardet 自动检测编码，解决了大量老文档的中文乱码问题
3. **容错处理**：任何格式解析失败时，自动尝试当作纯文本读取

## 解析性能如何？大文件需要多久

## 听说过Markitdown吗？

## 为什么要分块？块大小如何确定？

在内测的时候，遇到一个问题，索引几个30MB的txt文件时，系统内存占用拉满

我通过关键节点打印内存监控日志，定位到是Bleve在索引阶段

分析后发现索引时需要同时保存原文档、倒排索引、分词结果，内存占用是文档大小的 **3-5 倍**

我设计了**分块 + 批量 + 限流**的三层方案

1. 将大文档按 **1MB** 切分为多个小块
2. 累积 **10MB** 数据后才提交一次 Batch
3. Sleep 让 Bleve 后台线程有时间刷盘

块大小的确定都是通过不断测试得出的最佳结论

## 聚合算法是什么？时间复杂度是多少？

1. 遍历搜索结果，判断是主文档还是分块；主文档保存到 Map，分块的高亮保存到另一个 Map
2. 如果只匹配到分块，没匹配到主文档，需要主动查询主文档信息
3. 按顺序遍历主文档 ID，拼接高亮内容，取前 5 个片段