# **传统哈希表**

本文介绍一下Go的map。

本质上map是一个封装好的哈希表，物理底层是数组，读写时间是O(1)

那哈希表做了什么？将任何内容转为下标：hash(key)，然后取模，接着定位

然后空间是有限的，咱们要存那么多key，必然会有冲突。

解决方法有

**链式（`chaining`）**
如果多个键映射到同一位置，这些键和值就会存储在一个链表中

实际应用中，许多哈希表的实现**会使用一个大的链表**，把所有有值的槽位串联起来以节省内存

优点：实现简单；插入删除快

缺点：不利于缓存局部性（在链表中，元素是分散存储在内存中的，每次访问一个链表节点时，可能需要加载不相邻的内存地址


**开放寻址/线性探测（`linear probing`）**

从冲突位置开始依次搜索，直到找到空槽位

优点：内存节省，无额外开销；较好的缓存局部性，连续内存

缺点：可能退化为 O(n) 时间复杂度（负载因子接近 1）；扩容的次数会比链表法更多


# Go Map原数据存储

**Go Map（1.24 之前）采用**链式 + 开放结合**的变体**，下面介绍其具体实现
简单来说，就是一个map 有2^n个桶，每个桶有8个槽位。

1. 查找
    1. 给一个key，hash之后，先用低n位查找落在哪个桶；然后遍历比较高8位tophash，都找不到就去溢出桶。
    2. 每个桶里面tophash 放一起，key放一起，value也单独放，节省内存。
2. 增加
    1. 查找到桶内并顺序插入
    2. 如果一个桶的 8 个槽位满了 就挂一个 overflow bucket继续存
3. 删除
    1. 找到桶和槽位，把 tophash 标记为 emptyOne，把键值设为零值
4. 扩容
    1. 等量扩容，溢出桶过多，为消灭 overflow 链；负载因子过高，翻倍扩容。
    2. 维护两个桶。操作时“搬运”操作的桶。新的只插入新桶
    3. 由 nevacuate 标记迁移进度。查找、删除都比较这个，看去哪里


# **SwissTable**

为了进一步的优化性能、缓存命中率，Go从桶换成了SwissTable

简单来说，SwissTable就是

1. 一个map有多个group，每个group有16个槽位，每个槽位有一个 **metadata**
2. 给一个key，进行hash之后。得到一个64bit的数。
    1. 哈希值的高57bit被称为H1，用于定位 **哪个 Group**
    2. 低7bit被称为H2。放在metadata中存储，用于快速过滤。
    3. 左侧再加一位，用于特殊含义：如果是1000 0000，说明是空，如果是1111 1110，说明是deleted / tombstone，如果是0xxx xxxx说明满了
3. 这里有个SIMD(Single Instruction, Multiple Data)的知识点，一条指令，同时处理多个数据。
    1. 在SwissTable的过滤metadata中，我们不是for循环逐个比较，而是使用SIMD方法一次性比较16个。
    2. CPU提供了向量寄存器，可以在一条指令中比较多个字节
    3. 查询时，先将目标 Key 的 H2 **广播**填充至整个向量寄存器
    4. 再将 Group 的 16 个 Metadata **一次性加载**进另一个寄存器。
    5. 利用 SIMD 指令让这两组数据**一触碰**，就能瞬间筛选出所有匹配的 Slot


Swiss Table 最大优势在 SIMD

# Go 1.24实现

做了点适配，首先是一个map有多个table，这样就能避免全局扩容，只是某个table内部进行扩容

我们可以看到这里有个Directoy和GlobelDepth，然后分两种情况

1. 通常情况下，Directory指向Table数组，表的长度就是GlobalDepth的两倍。比如Depth为2，长度就是4，我们就用高位的前两位来定位在哪个Table，比如01 10，当然可能多个条目指向一个Table。
2. 当元素非常小时，Directory会指向一个单独的组Group，并将表长度置为0。

## 1. 初始化流程

1. 分配Map对象
2. 如果只存8个以内的元素，直接返回
    1. 编译器介入，如果比较小，那么可能已经分配好了一个group空间，并直接塞给了dirPtr
    2. 如果编译器没分配，我也不分配
3. 如果大于8个，进行计算分配，然后实例化目录与表


## 2. 操作流程

**查找流程**

1. 根据哈希值的高位构造探测序列
2. 循环遍历
    1. SIMD快速匹配候选人
    2. 逐个比较候选人的键
        1. 如果找到，返回值
        2. 如果未找到，那么继续看是否有空元素
            1. 有则说明探测终止，直接返回未找到
            2. 无空元素，那就根据探测序列跳到下一个Group，继续找


**修改、增加流程**

1. 根据哈希值的高位构造探测序列
2. 循环遍历
    1. SIMD快速匹配候选人
    2. 逐个比较候选人的键
        1. 如果找到，直接更新，退出
        2. 如果未找到，看是否有墓碑
            1. 有则记录第一个墓碑在哪，继续找
        3. 未找到，并且到达终点，优先填坑墓碑，不行就填坑空位
    3. 没位置则进行扩容


**删除流程**

1. 根据哈希值的高位构造探测序列
2. 循环遍历
    1. SIMD快速匹配候选人
    2. 逐个比较候选人的键
        1. 如果找到, 是指针就清零, 不是指针就清内存
        2. 然后看组里有没有空位
            1. 有，说明是探测序列终点，可以置metadata为空
            2. 没有，说明组内满员，不是终点，置为墓碑（ctrlDeleted）
        3. 未找到，则继续，直到到达终点

## 3. 扩容流程

1. 计算当前容量*2是否小于规定的单表最大限制
    1. 小于，则翻倍扩容，分配一个两倍大的新表，把旧数据重新哈希搬过去
    2. 否则分裂扩容，创建两个最大容量的新表，数据分流搬迁

## 4. 边遍历边修改

由于 Go 慷慨的迭代语义，迭代是 Map 中最复杂的部分。规范中的语义摘要：

1. 在迭代期间添加和/或删除条目绝不能导致迭代多次返回同一个条目。
2. 在迭代期间添加的条目可能会被迭代返回。
3. 在迭代期间修改的条目必须返回其最新值。
4. 在迭代期间删除的条目绝不能被迭代返回。
5. 迭代顺序是未指定的。在实现中，它是被显式随机化的。

直接遍历旧表，然后读值的时候读新表

# Map 并发安全吗？

**结论：不安全。**

- **竞态条件**：多个 Goroutine 同时读写会触发 fatal("concurrent map writes")
- **检测机制**：Map 内部有一个 writing 标志位。任何写操作开始前会检查该位，并将其设为“正在写入”。如果此时发现已经被设为“正在写入”，直接抛出 `fatal error`。
- **解决方案**：
    1. **`sync.Mutex`**：最通用，写锁保护。
    2. **`sync.RWMutex`**：读多写少场景，性能更好。
    3. **`sync.Map`**：官方提供的并发版 Map，适合“读多写少”且“键不怎么变化”的特定场景。
    4. **分段锁**：将一个大 Map 拆分成多个小 Map，减少锁竞争（类似 Java 的ConcurrentHashMap 原理）