# **传统哈希表**

我们知道map就是能够o1时间取出来对吧，底层实现是hashtable

hashtable底层是数组，知道下标马上能取出来

那hashtable做了什么？将任何内容转为下标：hash(key)，然后取模，接着定位

然后空间是有限的，咱们要存那么多key，必然会有冲突。

解决方法有

**链式（`chaining`）**
如果多个键映射到同一位置，这些键和值就会存储在一个链表中

实际应用中，许多哈希表的实现**会使用一个大的链表**，把所有有值的槽位串联起来以节省内存

优点：实现简单；插入删除快

缺点：不利于缓存局部性（在链表中，元素是分散存储在内存中的，每次访问一个链表节点时，可能需要加载不相邻的内存地址


**开放寻址/线性探测（`linear probing`）**

从冲突位置开始依次搜索，直到找到空槽位

优点：内存节省，无额外开销；较好的缓存局部性，连续内存

缺点：可能退化为 O(n) 时间复杂度（负载因子接近 1）；扩容的次数会比链表法更多

# Go Map原数据存储

**Go Map（1.24 之前）采用**链式 + 开放结合**的变体**，下面介绍其具体实现
简单来说，就是

1. 一个map 有2^n个桶，每个桶有8个槽位。
2. 查找
    1. 给一个key，hash之后，先用低n位查找落在哪个桶；然后遍历比较高8位tophash，都找不到就去溢出桶。
    2. 每个桶里面tophash 放一起，key放一起，value也单独放，节省内存。
3. 增加
    1. 查找到桶内并顺序插入
    2. 如果一个桶的 8 个槽位满了 就挂一个 overflow bucket继续存
4. 删除
    1. 找到桶和槽位，把 tophash 标记为 empty/deleted
    2. key/value 可以置为零值（或者不动，依赖 GC 回收）
5. 扩容
    1. 等量扩容，溢出桶过多，为消灭 overflow 链；负载因子过高，翻倍扩容。
    2. 维护两个桶。操作时搬运小部分。新的只插入新桶
    3. 由 nevacuate 标记迁移进度。查找、删除都比较这个，看去哪里

# **SwissTable**

1. 一些性能和延迟敏感的业务场景觉得**Go map不够快**，
2. 另外一个常被诟病的就是当前实现的桶扩容后就不再缩容(shrink)了
3. 缓存利用率低：链表的“随机跳跃”、内存浪费：Padding（内存对齐）问题

简单来说，就是

1. 一个map有多个group，每个group有16个槽位，每个槽位有一个 **metadata**
2. 给一个key，hash之后。得到一个8字节64bit的数。
    1. 哈希值的高57bit被称为H1，用于定位 **哪个 Group**，查找和插入时都需要它
    2. 低7bit被称为H2。被用于该元素的元数据，放在metadata中存储，通过SIMD指令从16个位置中快速得到匹配的pos
    3. 这 7 位会成为控制字节的末尾 7 位，然后控制字节的第一位会有特殊含义
        
        ```
        0b11111111  // EMPTY (all bits are set)
        0b10000000  // DELETED (top bit is set) (tombstone)
        0b0.......  // FULL (whenever the top bit isn't set)
        ```
        
    4. SIMD(Single Instruction, Multiple Data)：传统方法for 循环逐个比较 → 最多访问 16 次 metadata；SIMD 方法一次指令比较全部 16 个 → 几乎零循环开销


Swiss Table 最大优势在 SIMD

# Go 1.24实现

```markdown
Map → Directory → 多个 Table → 每个 Table 由多个 Group 组成

1. Directory：全局目录，table 的数组，根据 hash 前缀分配数据到不同的 Table
2. Table：真正存放 key/value 的哈希表片段
3. Group：Table 内较小单位，每个 Group 有 8 个槽位和 control bytes
4. GlobalDepth：目录（directory）数组用多少位 hash 选择 table
5. LocalDepth：每个 table 内管理 hash 空间的位数。这个 table 内的 key 只看 hash 的高 localDepth 位
```


## 1. Table、Directory、GlobalDepth和LocalDepth的作用

GlobalDepth：我现在“表有多大”。

1. 位置数量=2^globalDepth
2. 目录（directory）数组用多少位 hash 选择 table

LocalDepth：这个 table“认多大的表”。

1. 比如是local是1，global是3，101或者100可能都是这个table
2. local<global，就说明好几个目录指向它；local≥global，桶又满了的时候，才提高global

1. 都是为了可扩展哈希服务，如果某个 Table 满了，但它的 `LocalDepth < GlobalDepth`，Go 只需要把这**一个 Table** 拆成两个
2. 查找变得简单稳定，以前需要比对nevacutate，去旧表或新表找；现在查找流程都很统一


## 2. 边遍历边修改

1. The Go language spec explicitly allows modifications during iteration, with the following semantics:
    - If an entry is deleted before it is reached, it will not be produced.
    - If an entry is updated before it is reached, the updated value will be produced.
    - If a new entry is added, it may or may not be produced.
2. 直接遍历旧表，然后读值的时候读新表

## 3. 查找、插入、删除的操作流程

### **1. 查找流程**

计算 hash → 目录选 table → table 内选 group → group 内 H2 SIMD 匹配 → 精确 key 对比 → probe 序列跨组搜索


### **2. 插入流程**

计算 hash → 目录选 table → table 内选 group → group 内 H2 SIMD 匹配 → 精确 key 对比 → 有则更改，无则找第一个空槽或墓碑→ probe 序列跨组搜索

### **3. 删除流程**

查找流程之后

- 如果 group 内还有空 slot → 直接标记为空
- 如果 group 满 → 标记 tombstone（删除标记），保证 probe 不会提前结束
- tombstone 会在 grow/迁移时清理

**tombstone 是为了解决 probe 序列的正确性问题**：删除时保留占位让 probe 继续工作，避免 **probe**查找失败


# Map 并发安全？

**结论：不安全。**

- **竞态条件**：多个 Goroutine 同时读写会触发 `panic:oncurrent map writes`。
- **检测机制**：Map 内部有一个 `flags` 标志位。任何写操作开始前会检查该位，并将其设为“正在写入”。如果此时发现已经被设为“正在写入”，直接抛出 `fatal error`。
- **解决方案**：
    1. **`sync.Mutex`**：最通用，写锁保护。
    2. **`sync.RWMutex`**：读多写少场景，性能更好。
    3. **`sync.Map`**：官方提供的并发版 Map，适合“读多写少”且“键不怎么变化”的特定场景。
    4. **分段锁**：将一个大 Map 拆分成多个小 Map，减少锁竞争（类似 Java 的ConcurrentHashMap 原理）